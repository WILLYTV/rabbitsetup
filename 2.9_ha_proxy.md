# 2.9 – Setup de HAProxy para RabbitMQ (Instalação Offline)

## Cenário
- Dois nodes HAProxy em alta disponibilidade (HA), atuando como balanceadores para o cluster RabbitMQ.
- Instalação offline, sem acesso à internet.
- HAProxy distribui conexões dos clientes entre os nodes RabbitMQ.

---

## 1. Pré-requisitos
- Pacote HAProxy disponível localmente (RPM ou tar.gz).
- Acesso root nos nodes HAProxy.
- IPs/hosts dos nodes RabbitMQ conhecidos.

---

## 2. Instalação do HAProxy (Offline)
---

## 2.1. Preparação dos nodes dedicados ao HAProxy (03c e 04c)

Para usar os servidores 03c e 04c exclusivamente como HAProxy:


### 1. Pare e desabilite o RabbitMQ nos nodes 03c e 04c
Execute nos próprios nodes 03c e 04c:
```bash
sudo systemctl stop rabbitmq-server
sudo systemctl disable rabbitmq-server
```

### 2. Remova os nodes 03c e 04c do cluster RabbitMQ
Com os serviços já parados, execute em um node ativo do cluster (ex: 00c):
```bash
sudo rabbitmqctl forget_cluster_node rabbit@sncpos00903c
sudo rabbitmqctl forget_cluster_node rabbit@sncpos00904c
```
Isso garante que o cluster não acuse ausência desses nodes e mantenha o status saudável.

> **Observação:** O comando `forget_cluster_node` só funciona corretamente se o serviço RabbitMQ nos nodes a serem removidos estiver parado.


### 3. Instale o HAProxy offline nos nodes 03c e 04c

#### 3.1. Baixe o pacote RPM do HAProxy em um computador com acesso à internet
Versão recomendada: haproxy-2.4.22-1.el9.x86_64.rpm
URL oficial CentOS Stream 9:
```powershell
# Exemplo em ambiente Windows (PowerShell):
curl.exe -o haproxy-2.4.22-1.el9.x86_64.rpm "http://mirror.stream.centos.org/9-stream/AppStream/x86_64/os/Packages/haproxy-2.4.22-1.el9.x86_64.rpm"
```
Confirme o tamanho do arquivo baixado:
```powershell
Get-Item .\haproxy-2.4.22-1.el9.x86_64.rpm | Select-Object Length
```

#### 3.2. Faça o upload do arquivo para o diretório `/tmp` de cada node HAProxy
Use o Painel SFTP (drag-and-drop via MobaXterm) ou SCP:
```powershell
scp C:\caminho\haproxy-2.4.22-1.el9.x86_64.rpm usuario@IP_DO_NODE_HAPROXY:/tmp/
```

#### 3.3. Instale o pacote transferido
No node HAProxy, instale o pacote:
```bash
sudo dnf install /tmp/haproxy-2.4.22-1.el9.x86_64.rpm
```
Se houver dependências, baixe e transfira também os pacotes necessários e instale todos juntos:
```bash
sudo dnf install /tmp/haproxy-2.4.22-1.el9.x86_64.rpm /tmp/dependencia1.rpm /tmp/dependencia2.rpm
```

#### 3.4. Configure o HAProxy normalmente


Cole ao final do arquivo `/etc/haproxy/haproxy.cfg` os blocos abaixo, que apontam apenas para os nodes RabbitMQ ativos (00c, 01c, 02c):


#### Bloco para AMQP (porta 5672)
```haproxy
frontend rabbitmq_front
    bind *:5672
    default_backend rabbitmq_nodes

backend rabbitmq_nodes
    balance roundrobin
    server sncpos00900c sncpos00900c:5672 check
    server sncpos00901c sncpos00901c:5672 check
    server sncpos00902c sncpos00902c:5672 check
```

#### Bloco para AMQP com SSL/TLS (porta 5671)
```haproxy
frontend rabbitmq_front_ssl
    bind *:5671
    mode tcp
    default_backend rabbitmq_nodes_ssl

backend rabbitmq_nodes_ssl
    mode tcp
    balance roundrobin
    server sncpos00900c sncpos00900c:5671 check
    server sncpos00901c sncpos00901c:5671 check
    server sncpos00902c sncpos00902c:5671 check
```

#### Bloco para Management UI HTTP (porta 15672)
```haproxy
frontend rabbitmq_mgmt
    bind *:15672
    default_backend rabbitmq_mgmt_nodes

backend rabbitmq_mgmt_nodes
    balance roundrobin
    server sncpos00900c sncpos00900c:15672 check
    server sncpos00901c sncpos00901c:15672 check
    server sncpos00902c sncpos00902c:15672 check
```

#### Bloco para Management UI HTTPS (porta 15671)
```haproxy
frontend rabbitmq_mgmt_ssl
    bind *:15671
    mode tcp
    default_backend rabbitmq_mgmt_nodes_ssl

backend rabbitmq_mgmt_nodes_ssl
    mode tcp
    balance roundrobin
    server sncpos00900c sncpos00900c:15671 check
    server sncpos00901c sncpos00901c:15671 check
    server sncpos00902c sncpos00902c:15671 check
```

> **Importante:**
> - Realize a desativação do RabbitMQ apenas nos nodes 03c e 04c.
> - Configure o HAProxy para escutar nas portas padrão.
> - As aplicações devem apontar para os IPs/hostnames dos nodes HAProxy (03c e 04c) nas portas padrão.
---


---

## 3. Configuração do HAProxy

## 4. Inicialização do HAProxy

```bash
sudo systemctl enable --now haproxy
sudo systemctl restart haproxy   # Reinicie após alterar o haproxy.cfg
sudo systemctl status haproxy
```

---

## 5. Teste de funcionamento
- Conecte um cliente à porta 5672 do HAProxy e verifique se a conexão é distribuída entre os nodes RabbitMQ.
- Teste failover: pare um node RabbitMQ e veja se o HAProxy redireciona para os nodes ativos.

---

## 6. Alta disponibilidade do HAProxy (opcional)
- Para HA real, configure um VIP (Virtual IP) com Keepalived ou Pacemaker entre os dois nodes HAProxy.
- O VIP garante que, se um HAProxy falhar, o outro assume automaticamente.
- Exemplo de configuração de Keepalived pode ser fornecido conforme necessidade.

---

## 7. Observações
- Não é necessário ajuste nos nodes RabbitMQ para uso com HAProxy.
- Garanta que as portas estejam liberadas no firewall dos nodes HAProxy e RabbitMQ.
- Documente os IPs/hosts usados no balanceamento para facilitar troubleshooting.

---

## 8. Endereço único e alta disponibilidade

Para que as aplicações utilizem um único endereço externo (IP ou hostname) e tenham alta disponibilidade, é necessário configurar um VIP (Virtual IP) entre os dois nodes HAProxy usando Keepalived ou Pacemaker.

**Exemplo de instrução para Keepalived:**

1. Instale o Keepalived em ambos os nodes HAProxy:
    ```bash
    sudo dnf install keepalived
    ```
2. Configure o arquivo `/etc/keepalived/keepalived.conf` em ambos os nodes, definindo o mesmo VIP (ex: 10.10.10.100) e prioridade diferente para cada node.
3. Inicie e habilite o serviço:
    ```bash
    sudo systemctl enable --now keepalived
    sudo systemctl status keepalived
    ```
4. As aplicações devem apontar para o VIP configurado, e não para os IPs individuais dos nodes HAProxy.

> **Alternativas:**
> - Em ambientes mais avançados, pode-se usar Traefik, Consul ou Route53 para balanceamento, descoberta de serviços e failover dinâmico.
> - Essas soluções permitem automação, DNS dinâmico, health-checks e integração com cloud ou containers.
> - Para ambientes on-premise e simples, o VIP com Keepalived é a solução mais direta e robusta.

Se desejar instruções detalhadas para Traefik, Consul ou Route53, solicite conforme o contexto do seu ambiente.

---

> **Dica:** Para ambientes offline, mantenha todos os pacotes necessários em um repositório local ou mídia removível.
